# Отчёт по домашнему заданию №2: Практическое исследование кластера Apache Kafka в режиме KRaft

## 1. Выполнение задания и полученные результаты

### 1.1 Подготовка и запуск кластера

Для выполнения задания был клонирован предоставленный репозиторий и запущен Docker-кластер Kafka в режиме KRaft. После выполнения команды `docker compose up -d` успешно запустились три брокера: **kafka01, kafka02 и kafka03**.

Кластер был проверен с помощью Kafka UI, доступного по адресу `http://localhost:8080`. На скриншоте ниже видно, что все три брокера активны, а контроллером кластера является брокер **kafka01** (ID: 1).

![Состояние кластера после запуска](img/image.png)

*Рисунок 1: Состояние кластера после запуска (брокер kafka01 является контроллером)*

Создан тестовый топик `test_topic` со следующими параметрами:
- Количество партиций: **8**
- Фактор репликации: **3**

![Список топиков в кластере](img/topics.png)

*Рисунок 2: Список топиков в кластере*

### 1.2 Анализ характеристик топика

Настройки созданного топика `test_topic` были проанализированы в Kafka UI:

![Детальная информация о топике test_topic](img/our_topic.png)

*Рисунок 3: Детальная информация о топике test_topic*

**Ключевые характеристики и их назначение:**

1. **Количество партиций (8)**
   - **Назначение**: Партиции позволяют достичь параллелизма при обработке данных. Каждая партиция может обрабатываться отдельным потребителем (consumer) в consumer-группе.
   - **Что если их не будет?**: Если бы топик имел только одну партицию, это стало бы узким местом для производительности, так как все сообщения должны были бы обрабатываться последовательно одним потребителем.
   - **Отказоустойчивость**: Наличие 8 партиций обеспечивает лучшую распределенность данных по брокерам и повышает отказоустойчивость.

2. **Фактор репликации (3)**
   - **Назначение**: Каждая партиция реплицируется на 3 брокера. Одна из реплик является лидером (leader), остальные — последователями (followers).
   - **Механизм работы**: Как объясняется в статье про основы репликации в Kafka, "лидер отвечает за прием и запись всех новых сообщений в партиции" и "регулярно отправляет данные фолловерам".
   - **Отказоустойчивость**: Топик может пережить отказ до 2 брокеров одновременно без потери данных. Для кворума в 3 узлах необходимо 2 живых узла.

3. **In-Sync Replicas (ISR)**
   - **Все реплики синхронизированы** (3 из 3), что означает, что все фолловеры успешно синхронизируются с лидером.
   - **Важность**: Только реплики из ISR могут стать лидерами при отказе текущего лидера.

### 1.3 Нагрузочное тестирование

Для нагрузочного тестирования была выполнена команда отправки 1 000 000 сообщений:
```bash
docker run -it --rm --network kafka-kraft-cluster_default confluentinc/cp-kafka /bin/kafka-producer-perf-test --topic test_topic --num-records 1000000 --throughput -1 --producer-props bootstrap.servers=kafka01:9092,kafka02:9092,kafka03:9092 batch.size=16384 acks=1 linger.ms=50 --record-size 1000
```

**Результаты нагрузочного тестирования:**

```
1000000 records sent, 152671.338385 records/sec (145.59 MB/sec), 7.67 ms avg latency, 802.00 ms max latency, 5 ms 50th, 35 ms 95th, 84 ms 99th, 418 ms 99.9th.
```

**Анализ результатов:**

1. **Throughput**:
   - **152,671 RPS**
   - **145.59 MB/сек**
   - Высокие показатели достигнуты благодаря параллельной записи в 8 партиций и оптимизированным настройкам producer'а

2. **Latency**:
   - **Средняя задержка**: 7.67 мс
   - **Максимальная задержка**: 802 мс (кратковременные пики)
   - **Процентили**: 50th: 5 мс, 95th: 35 мс, 99th: 84 мс

3. **Параметры producer'а и их влияние**:
   - `acks=1`: Producer ждет подтверждения только от лидера, что дает баланс между производительностью и надежностью.
   - `batch.size=16384`: Размер батча в 16 КБ позволяет эффективно группировать сообщения.
   - `linger.ms=50`: Producer ждет до 50 мс для заполнения батча, улучшая компрессию и эффективность сети.

**Подтверждение доставки сообщений в Kafka UI:**

После завершения теста в Kafka UI было подтверждено, что все 1 000 000 сообщений успешно доставлены и распределены по всем трем брокерам.

### 1.4 Тестирование отказоустойчивости

#### Тест 1: Остановка контроллера kafka01

После запуска скрипта `example.py`, отправляющего сообщения каждые 0.5 секунд, был остановлен контейнер с контроллером (kafka01):

```bash
docker stop kafka-kraft-cluster-kafka01-1
```

**Наблюдения:**
1. Kafka UI показал, что **kafka01 перешел в состояние "Неактивен"**
2. **kafka02 автоматически стал новым контроллером** (выбор лидера через механизм Raft)
3. Скрипт продолжает успешно отправлять сообщения без ошибок
4. Данные продолжают поступать в топик `critical_data`

**Механизм выбора нового контроллера:**
Согласно документации по распределенным системам координации, Raft — это консенсусный алгоритм, где "узлы используют рандомизированный тайм-аут для выбора лидера, гарантируя, что выбирается только один лидер". В нашем случае оставшиеся два узла (kafka02 и kafka03) провели выборы, и kafka02 стал новым контроллером.

#### Тест 2: Остановка второго брокера kafka02

После остановки второго брокера (теперь контроллера):

```bash
docker stop kafka-kraft-cluster-kafka02-1
```

**Наблюдения:**
1. **Программа прекратила отправку данных** с ошибкой подключения к кластеру
2. **Кворум потерян**: Из 3 узлов остался только 1 живой (kafka03), что недостаточно для кворума (необходимо 2 из 3)
3. **Kafka UI перестал отвечать**, так как для работы метаданных также требуется кворум
4. Логи последнего живого брокера (kafka03) показывают ошибки подключения и отсутствие кворума

**Объяснение ситуации с ISR:**
ISR — это набор реплик, которые синхронизированы с лидером. Когда две из трех реплик становятся недоступными, оставшаяся реплика не может образовать кворум. Как объясняется в материалах по репликации Kafka, "Kafka гарантирует, что записи завершаются только после того, как они будут сохранены на лидере и у минимального числа реплик". При `min.insync.replicas=2` (неявное требование для кворума) и наличии только одной живой реплики запись становится невозможной.

#### Тест 3: Восстановление кластера

**Восстановление первого брокера:**
```bash
docker start kafka-kraft-cluster-kafka01-1
```

После восстановления kafka01:
1. Кластер **восстановил кворум** (2 из 3 узлов доступны)
2. Программа **возобновила отправку сообщений** без вмешательства пользователя
3. **Автоматическая синхронизация данных**: kafka01 начал синхронизироваться с лидером (kafka03)

**Восстановление второго брокера (kafka02):**
```bash
docker start kafka-kraft-cluster-kafka02-1
```

После полного восстановления кластера:
1. Все три брокера активны и синхронизированы
2. **Данные консистентны** на всех репликах благодаря механизму репликации Kafka
3. **Автоматическое перераспределение лидерства**: Произошло автоматическое перераспределение лидеров партиций для балансировки нагрузки

## 2. Выводы и анализ

### 2.1 Механизмы отказоустойчивости Kafka

1. **Репликация данных**: Благодаря фактору репликации 3, каждая партиция хранится на трех брокерах, что обеспечивает сохранность данных при отказе до двух брокеров.

2. **Консенсусный протокол Raft**: В отличие от старой архитектуры с ZooKeeper, Kafka теперь использует встроенный механизм Raft для выбора контроллера и управления метаданными. Это упрощает администрирование и повышает надежность.

3. **Кворумная система**: Кластер из 3 узлов требует 2 живых узла для принятия решений. Это обеспечивает консистентность данных ценой доступности при потере кворума.

### 2.2 Производительность и масштабируемость

1. **Параллелизм через партиции**: 8 партиций в топике позволяют достичь высокой пропускной способности (152K RPS) за счет параллельной обработки.

2. **Балансировка нагрузки**: Kafka автоматически распределяет лидерство партиций между брокерами, что обеспечивает равномерную нагрузку.

3. **Настройки producer'а**: Параметры `acks`, `batch.size` и `linger.ms` существенно влияют на баланс между производительностью и надежностью.

### 2.3 Практические рекомендации для production

1. **Размещение брокеров**: В production-среде брокеры должны работать на отдельных физических или виртуальных машинах для обеспечения настоящей отказоустойчивости.

2. **Мониторинг ISR**: Критически важно мониторить размер ISR для каждой партиции, так как выход реплик из ISR снижает отказоустойчивость.

3. **Планирование емкости**: Выбор количества партиций должен основываться на ожидаемой нагрузке и количестве consumer'ов.

4. **Тестирование отказоустойчивости**: Регулярное тестирование сценариев отказа необходимо для проверки восстановления кластера.

## 3. Заключение

В ходе выполнения домашнего задания был успешно развернут и протестирован кластер Apache Kafka в режиме KRaft. Практические эксперименты подтвердили ключевые архитектурные принципы Kafka:

1. **Высокая производительность**: Кластер показал способность обрабатывать более 150K сообщений в секунду с низкой задержкой.

2. **Отказоустойчивость**: Кластер автоматически восстанавливался после отказа контроллера без потери данных и перерывов в работе.

3. **Консистентность данных**: Механизмы репликации и консенсуса Raft обеспечивают целостность данных даже в условиях сбоев.
